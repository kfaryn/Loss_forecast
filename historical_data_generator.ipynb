{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c078e2",
   "metadata": {},
   "source": [
    "### Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507bc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Do otwarcia zip z url\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6feedd",
   "metadata": {},
   "source": [
    "### Pliki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb47a5e",
   "metadata": {},
   "source": [
    "`Plik główny`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f3868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLIK Z LIKWIDACJAMI\n",
    "path = './likwidacje/'\n",
    "likwidacje= pd.concat([pd.read_csv(path+part, sep=\";\", decimal=\",\") for part in os.listdir(path)])\n",
    "\n",
    "# NAGŁÓWKI\n",
    "likwidacje = likwidacje.rename(columns={'Miesiąc utworzenia':'CALMONTH','Sklep':'STORE','Artykul':'ARTICLE','Dzień utworzenia':'CALDAY','Informacja inw.':'TYPE','Wartość':'VALUE'}).reset_index().drop('index',axis=1)\n",
    "\n",
    "# TYP DANYCH\n",
    "likwidacje['CALDAY'] = pd.to_datetime(likwidacje['CALDAY'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f95d7c8",
   "metadata": {},
   "source": [
    "`Plik z kategoriami poduktowymi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1818ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLIK Z KATEGORIAMI \n",
    "kategorie = pd.read_csv('kategorie.csv', encoding = 'utf-8', sep=';', decimal=',', dtype ={'Artykul':int}).dropna(axis = 0, how = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb73f7",
   "metadata": {},
   "source": [
    "`Czyszczenie pliku głównego i łączenie z kategoriami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "534d8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Łączenie z kategoriami\n",
    "likwidacje = likwidacje.merge(kategorie[['ARTICLE','ARTICLE_CODE']].drop_duplicates(), on='ARTICLE_CODE', how='left')\n",
    "\n",
    "# WYWALANIE OUTLIERÓW, KTÓRE SĄ NIERACJONALNYMI WARTOŚCIAMI CO DO WARTOŚCI BEZWGLĘDNEJ\n",
    "likwidacje = likwidacje[~(likwidacje.VALUE.abs() >1000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c1e2e",
   "metadata": {},
   "source": [
    "`Czyszczenie likwidacji z outlierów`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ea67b",
   "metadata": {},
   "source": [
    "* likwidacje_pozostale - przechowuje informacje o stratach podlegających pod ubezpieczenie \n",
    "* likwidacje_inwentaryzacje - przechowuje informacje o stratach z tytułu inwentaryzacji \n",
    "* likwidacje - nie zawierają strat podlegających pod ubezpieczenie  i z tytułu inwentaryzacji\n",
    "\n",
    "W przypadku chęci stworzenia pliku _DANE_STARTOWE_INWENTARYZACJE.csv_ należy postawić symbol __#__ przed resztą linijek i odpowiednio wstawić _likwidacje_inwentaryzacje_ w zaznaczonym niżej miejscu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b337490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "likwidacje_pozostale = ...\n",
    "likwidacje_inwentaryzacje = ...\n",
    "likwidacje = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ffd37",
   "metadata": {},
   "source": [
    "`Czyszczenie likwidacji z odstającymi rodzajów dokumentów`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5fc22",
   "metadata": {},
   "source": [
    "* likwidacje_odstajace - przechowuje informacje o stratach posiadających bardzo nieregularny wzorzec \n",
    "* likwidacje - nie zawierają strat posiadających bardzo nieregularny wzorzec\n",
    "\n",
    "W przypadku chęci stworzenia pliku _DANE_STARTOWE_ODSTAJACE.csv_ należy postawić symbol __#__ przed resztą linijek i odpowiednio wstawić _likwidacje_odstajace_ w zaznaczonym niżej miejscu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50439146",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "TUTAJ ODPOWIEDNIO ZMIENIĆ W ZALEŻNOŚCI OD POTRZEB\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e53964",
   "metadata": {},
   "source": [
    "Należy uzupełnić według wzoru:  _likiwdacje_ = _ _ _ _ _ _ _, gdzie należy wstawić:  \n",
    "* likwidacje - w celu wygenerowania _'DANE_STARTOWE_OCZYSZCZONE.csv'_\n",
    "* likwidacje_inwentaryzacje - w celu wygenerowania _'DANE_STARTOWE_INWENTARYZACJE.csv'_\n",
    "* likwidacje_odstajace - w celu wygenerowania _'DANE_STARTOWE_ODSTAJACE.csv'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7d1e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grupowanie bez podziału na kategorie\n",
    "likwidacje = likwidacje.groupby(['STORE','CALMONTH','CALDAY'])[['STORE','VALUE', 'TYPE', 'CALDAY', 'CALMONTH']].agg({'VALUE':'sum', 'TYPE': (lambda x: Counter(x))}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4623c4",
   "metadata": {},
   "source": [
    "### Dane zewnętrzne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5c7ee",
   "metadata": {},
   "source": [
    "`Charakterystyki dni`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5df5094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalendarz = pd.read_excel('dane_predykcje.xlsx', sheet_name= 'zmienne_swieta')\n",
    "\n",
    "# Do ustawienia\n",
    "kalendarz = kalendarz[(kalendarz.data>'2019-06-30')&(kalendarz.data<'2023-02-01')]\n",
    "\n",
    "# Połączenie\n",
    "likw = []\n",
    "for sklep in likwidacje.STORE.unique():\n",
    "    dla_sklepu = likwidacje[likwidacje.STORE == sklep]\n",
    "    tab = pd.merge(kalendarz,dla_sklepu, left_on='data', right_on='CALDAY', how='left')\n",
    "    tab['STORE'] = sklep\n",
    "    tab['CALDAY'] = tab['data']\n",
    "    tab['CALMONTH'] = (tab['CALDAY'].dt.year.astype(str) + tab['CALDAY'].dt.month.map(\"{:02}\".format).astype(str)).astype(int)\n",
    "    likw.append(tab)\n",
    "likwidacje = pd.concat(likw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f381d9",
   "metadata": {},
   "source": [
    "`Plik z informacjami o sklepach własnych`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed7a1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklepy_informacje = pd.read_excel('dane_predykcje.xlsx', sheet_name= 'dane_sklepy_dc')\n",
    "\n",
    "# Dodanie informacji o sklepach do likwidacji\n",
    "likwidacje = likwidacje.merge(sklepy_informacje, on = 'STORE', how = 'left')\n",
    "likwidacje = likwidacje[likwidacje.STORE.isin(list(sklepy_informacje.STORE.unique()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a358d43",
   "metadata": {},
   "source": [
    "`Plik z numerami sklepów SAPowymi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a11d7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "numery = pd.read_excel('dane_predykcje.xlsx', sheet_name= 'numeracja_sklepy_dc', header = 1)\n",
    "numery = numery.rename(columns = {'Sklep (Kod)': 'STORE','Numer sklepu Detal':'NUMER_SKLEPU'})\n",
    "numery = numery.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4505b6e",
   "metadata": {},
   "source": [
    "`Plik z datami inwentaryzacji`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "202aa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "inwentaryzacje = pd.read_excel('dane_predykcje.xlsx', sheet_name= 'daty_inwentaryzacji_dc')\n",
    "inwentaryzacje['INVENTORY'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6d058",
   "metadata": {},
   "source": [
    "`Dane pogodowe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b8e24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacje = [100, 105, 115, 120, 125, 135, 155, 160, 185, 195, 200, 205, 210, 230, 235, 250, 270, 272, 280, 295, 300, 310, 330, 360, 375, 385, 399, 400, 415, 418, 424, 435, 455, 465, 469, 488, 495, 497, 500, 510, 520, 530, 540, 550, 560, 566, 570, 575, 580, 585, 595, 600, 625, 628, 650, 660, 670, 690]\n",
    "miesiące = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "start = 2019\n",
    "lata = []\n",
    "for i in range(4):\n",
    "    lata.append(start+i)\n",
    "    \n",
    "# DO 2022 ROKU WŁĄCZNIE\n",
    "\n",
    "appended_data = []\n",
    "kolumny_pogoda = pd.read_excel('dane_predykcje.xlsx', sheet_name= 'pogoda_kolumny', header = None)\n",
    "kolumny_do_usunięcia = ['Status pomiaru NOS', 'Status pomiaru FWS', 'Status pomiaru TEMP', 'Status pomiaru CPW', 'Status pomiaru WLGS','Status pomiaru PPPS', 'Status pomiaru PPPM', 'Status pomiaru WODZ', 'Status pomiaru WONO']\n",
    "for i in stacje:\n",
    "    for ii in lata:\n",
    "        try:\n",
    "            r = requests.get(f\"https://danepubliczne.imgw.pl/data/dane_pomiarowo_obserwacyjne/dane_meteorologiczne/dobowe/synop/{str(ii)}/{str(ii)}_{str(i)}_s.zip\")\n",
    "            files = ZipFile(BytesIO(r.content))\n",
    "            pogoda = pd.read_csv(files.open(f\"s_d_t_{str(i)}_{str(ii)}.csv\"), header = None, encoding = 'windows-1250')\n",
    "            pogoda.columns = list(kolumny_pogoda.iloc[:,0])\n",
    "            pogoda.drop(kolumny_do_usunięcia, axis=1, inplace=True)\n",
    "            appended_data.append(pogoda)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "appended_data = pd.concat(appended_data)\n",
    "\n",
    "# ROK 2023 - W RAZIE JAKBY ZMIENIŁO SIĘ Z NOWYM ROKIEM TO TO ZMIENIĆ!\n",
    "\n",
    "appended_data2 = []\n",
    "for i in miesiące:\n",
    "        try:\n",
    "            r = requests.get(f\"https://danepubliczne.imgw.pl/data/dane_pomiarowo_obserwacyjne/dane_meteorologiczne/dobowe/synop/2023/2023_{i}_s.zip\")\n",
    "            files = ZipFile(BytesIO(r.content))\n",
    "            pogoda = pd.read_csv(files.open(f\"s_d_t_{i}_2023.csv\"), header = None, encoding = 'windows-1250')\n",
    "            pogoda.columns = list(kolumny_pogoda.iloc[:,0])\n",
    "            pogoda.drop(kolumny_do_usunięcia, axis=1, inplace=True)\n",
    "            appended_data2.append(pogoda)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "appended_data2 = pd.concat(appended_data2)\n",
    "\n",
    "# ZŁĄCZONE DANE ZA WSZYSTKIE LATA\n",
    "\n",
    "pogoda = pd.concat([appended_data, appended_data2], ignore_index=True)\n",
    "\n",
    "# Errata do danych\n",
    "'''\n",
    "Stacja Katowice-Muchowiec do 31.12.2018 to stacja Katowice\n",
    "Stacja Łóź-Lublinek do 31.12.2018 to stacja Łóź\n",
    "Stacja Poznań-Ławica do 31.12.2018 to stacja Poznań\n",
    "Stacja Warszawa-Okęcie do 31.12.2018 to stacja Warszawa\n",
    "Stacja Wrocław-Strachowice do 31.12.2018 to stacja Wrocław\n",
    "Stacja Elbląg-Milejewo do 31.03.2013 to stacja Elbląg w inej lokalizacji, system nie pozwala przechowywać podwójnej nazwy stacji dla tego samego kodu.\n",
    "Stacja Resko-Smólsko do 31.12.2014 to stacja Resko.\n",
    "Stacja Kołobrzeg-Dźwirzyno do 8.04.2018 to stacja Kołobrzeg, nastąpiła zmiana lokalizacji stacji z zachowaniem kodu.\n",
    "''' ;    \n",
    "\n",
    "pogoda['Nazwa stacji'] = pogoda['Nazwa stacji'].apply(lambda x: 'KOŁOBRZEG' if x == 'KOŁOBRZEG-DŹWIRZYNO' else \n",
    "                                                      ('WARSZAWA' if x == 'WARSZAWA-OKĘCIE' else\n",
    "                                                      ('RESKO' if x == 'RESKO-SMÓLSKO' else\n",
    "                                                      ('ELBLĄG' if x == 'ELBLĄG-MILEJEWO' else\n",
    "                                                      ('POZNAŃ' if x == 'POZNAŃ-ŁAWICA' else\n",
    "                                                      ('ŁÓDŹ' if x == 'ŁÓDŹ-LUBLINEK' else\n",
    "                                                      ('KATOWICE' if x == 'KATOWICE-MUCHOWIEC' else\n",
    "                                                      ('WROCŁAW' if x == 'WROCŁAW-STRACHOWICE' else x))))))))                                              \n",
    "                                                \n",
    "\n",
    "# Obróbka kolumn przed dołączeniem historycznych informacji o pogodzie\n",
    "pogoda['CALDAY'] = pd.to_datetime(dict(year=pogoda.Rok, month=pogoda.Miesiąc, day=pogoda.Dzień))\n",
    "pogoda = pogoda.rename(columns = {'Nazwa stacji':'STACJA_POGODOWA'})\n",
    "\n",
    "# Kolumny do połączenia\n",
    "pogoda_kolumny = ['Kod stacji', 'STACJA_POGODOWA', 'Średnie dobowe zachmurzenie ogólne [oktanty]', 'Średnia dobowa prędkość wiatru [m/s]',\n",
    " 'Średnia dobowa temperatura [°C]', 'Średnia dobowa wilgotność względna [%]', 'Średnia dobowe ciśnienie na poziomie stacji [hPa]', \n",
    " 'Średnie dobowe ciśnienie na pozimie morza [hPa]', 'Suma opadu dzień  [mm]', 'Suma opadu noc   [mm]', 'CALDAY']\n",
    "\n",
    "# Połączenie\n",
    "likwidacje = likwidacje.merge(pogoda[pogoda_kolumny], on = ['CALDAY','STACJA_POGODOWA'], how='left')\n",
    "likwidacje = likwidacje.dropna(subset='STACJA_POGODOWA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4233263",
   "metadata": {},
   "source": [
    "`Inflacja`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bcc28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflacja = pd.read_csv(\"https://stat.gov.pl/download/gfx/portalinformacyjny/pl/defaultstronaopisowa/4741/1/1/miesieczne_wskazniki_cen_towarow_i_uslug_konsumpcyjnych_od_1982_roku.csv\", encoding = 'windows-1250', sep=';', decimal=',')\n",
    "\n",
    "# USUNIĘCIE BEZSENSOWNYCH KOLUMN\n",
    "inflacja = inflacja.iloc[:,:6]\n",
    "\n",
    "# STWORZENIE KOLUMNY Z PRZYJAZNYM FORMATEM I NOWEJ Z OPÓŹNIENIEM ZMIENNEJ\n",
    "inflacja['Wskaźnik_inflacji'] = inflacja['Wartość'] - 100\n",
    "inflacja['Wskaźnik_inflacji_lag'] = inflacja['Wskaźnik_inflacji'].shift(1)\n",
    "\n",
    "# Obróbka ramki i kolumn\n",
    "inflacja = inflacja[(inflacja['Sposób prezentacji'] == 'Analogiczny miesiąc poprzedniego roku = 100') & (inflacja['Rok']>2015)]\n",
    "inflacja['Miesiąc'] = inflacja.Miesiąc.map(\"{:02}\".format)\n",
    "inflacja['CALMONTH'] = inflacja.Rok.astype(str) + inflacja['Miesiąc']\n",
    "inflacja['CALMONTH'] = inflacja['CALMONTH'].astype(int)\n",
    "\n",
    "# Połączenie\n",
    "likwidacje = likwidacje.merge(inflacja[['Wartość', 'Wskaźnik_inflacji', 'Wskaźnik_inflacji_lag', 'CALMONTH']], on = 'CALMONTH', how='left').rename(columns = {'Wartość':'Wartość inflacji'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895e48f6",
   "metadata": {},
   "source": [
    "`Bezrobocie|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ab8f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Źródło: https://stat.gov.pl/obszary-tematyczne/rynek-pracy/bezrobocie-rejestrowane/bezrobotni-oraz-stopa-bezrobocia-wg-wojewodztw-podregionow-i-powiatow---styczen-grudzien-2004-r,2,3.html?contrast=default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3276aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bezrobocie = pd.read_excel('dane_predykcje.xlsx', sheet_name='bezrobocie_woj')\n",
    "\n",
    "bezrobocie = bezrobocie.drop(['WOJ.','POW.'], axis =1).set_index('powiat').stack().reset_index().rename(columns={'powiat':'WOJEWÓDZTWO','level_1':'CALMONTH',0:'UNEMP_RATE'})\n",
    "bezrobocie = bezrobocie.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "\n",
    "# Połączenie \n",
    "likwidacje  = likwidacje.merge(bezrobocie, on = ['WOJEWÓDZTWO','CALMONTH'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fe8ac",
   "metadata": {},
   "source": [
    "`Pozostałe dane makroekonomiczne publikowane dla kwartałów`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4621cd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "makroekonomiczne = pd.read_excel('dane_predykcje.xlsx', sheet_name='dane_makro').set_index('index').stack().reset_index().rename(columns={'level_1':'kwartał',0:'wartość'})\n",
    "\n",
    "# Ogranieczenie kwartałów i usunięcie niepotrzebnych spacji w wartościach\n",
    "makroekonomiczne = makroekonomiczne[~makroekonomiczne.kwartał.isin(['2022','2023','2024','2025'])].apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "# Zamiana tekstu na datę - kwartał\n",
    "makroekonomiczne['kwartał'] =  pd.to_datetime(makroekonomiczne['kwartał']).dt.to_period('Q')\n",
    "# Stworzenie ostatecznej tabelki \n",
    "makroekonomiczne = makroekonomiczne.pivot_table('wartość', 'kwartał','index').reset_index()\n",
    "\n",
    "# stworzenie w danych kolumny z kwartałem\n",
    "likwidacje['kwartał'] = pd.PeriodIndex(likwidacje.CALDAY, freq='Q')\n",
    "\n",
    "# połączenie\n",
    "likwidacje = likwidacje.merge(makroekonomiczne, on='kwartał', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db7e3bb",
   "metadata": {},
   "source": [
    "### Dane wewnętrzne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9f29b",
   "metadata": {},
   "source": [
    "`Stany magazynowe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99c72c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './zapasy/' # zapasy siedzą w folderze zapasy\n",
    "zapasy = pd.concat([pd.read_csv(path+part, sep=\"\\t\", decimal=\",\", encoding='cp1250') for part in os.listdir(path)])\n",
    "\n",
    "# Połączenie\n",
    "likwidacje = likwidacje.merge(zapasy[['CALDAY', 'STORE', 'STOCK_VALUE',\n",
    "       'STOCK_QUANTITY']], on = ['CALDAY','STORE'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5be574",
   "metadata": {},
   "source": [
    "`Nałożenie inwentaryzacji`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d988b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Połączenie - nałożenie inwentaryzacji\n",
    "likwidacje = likwidacje.merge(inwentaryzacje[['STORE','INVENTORY_DATE','INVENTORY']].drop_duplicates(), left_on = ['STORE','CALDAY'], right_on = ['STORE','INVENTORY_DATE'], how='left').drop('INVENTORY_DATE', axis=1)\n",
    "likwidacje['INVENTORY'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa8391",
   "metadata": {},
   "source": [
    "`Sprzedaż paragonowa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f779bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './sprzedaz/' # paragony siedzą w folderze sprzedaz\n",
    "paragony= pd.concat([pd.read_parquet(path+part) for part in os.listdir(path)])\n",
    "\n",
    "# KOLUMNA Z MIESIĄCEM - czyszczenie kolumn\n",
    "paragony['CALMONTH'] = paragony['CALDAY'].apply(lambda x: str(x)[:-2])\n",
    "paragony['ARTICLE'] = pd.to_numeric(paragony.ARTICLE)\n",
    "paragony['CALDAY'] = pd.to_datetime(paragony['CALDAY'])\n",
    "\n",
    "# Dodanie kategorii\n",
    "paragony = paragony.merge(kategorie[['ARTICLE_CODE','ARTICLE']].drop_duplicates(), on='ARTICLE_CODE', how='left')\n",
    "\n",
    "# Grupowanie\n",
    "paragony = paragony.groupby(['STORE','CALMONTH','CALDAY'])[['STORE','TOTAL_SALES', 'TOTAL_VOLUME_SOLD', 'CALDAY', 'CALMONTH']].agg({'TOTAL_SALES':'sum','TOTAL_VOLUME_SOLD': 'sum'}).reset_index()\n",
    "paragony['STORE'] = paragony['STORE'].astype(int)\n",
    "\n",
    "# Ewentualnie do korekty\n",
    "paragony.CALMONTH = paragony.CALMONTH.astype(int)\n",
    "\n",
    "# Połączenie\n",
    "likwidacje = pd.merge(likwidacje, paragony, on=['STORE','CALMONTH', 'CALDAY'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f6a70",
   "metadata": {},
   "source": [
    "`Nałożenie zmiany numerów sklepów w czasie`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3757096",
   "metadata": {},
   "source": [
    "`Zapisanie danych do pliku`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9486644",
   "metadata": {},
   "outputs": [],
   "source": [
    "likwidacje.to_csv('DANE_STARTOWE_OCZYSZCZONE.csv', index = False)\n",
    "likwidacje.to_csv('DANE_STARTOWE_INWENTARYZACJE.csv', index = False)\n",
    "likwidacje.to_csv('DANE_STARTOWE_ODSTAJACE.csv', index = False)\n",
    "likwidacje.to_csv('DANE_STARTOWE_WSZYSTKIE.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
