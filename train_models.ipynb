{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Biblioteki sktime\n",
    "import sktime\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster, EnsembleForecaster\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "from sktime.forecasting.model_selection import (ForecastingRandomizedSearchCV, ForecastingGridSearchCV, SingleWindowSplitter)\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.model_selection._split import temporal_train_test_split\n",
    "\n",
    "# metryki\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error, mean_squared_percentage_error,MeanSquaredError\n",
    "from sktime.transformations.series.feature_selection import FeatureSelection\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import wykres, compute_metrics, convert_and_preprocess_daily_to_monthly, convert_weekly_to_daily, convert_weekly_to_daily_xgb, convert_weekly_to_monthly, convert_weekly_to_monthly_xgb, wczytaj_dane_oczyszczone, get_most_important_cols, get_most_important_cols2, generate_confidence_intervals, wczytaj_dane_odstajace, wczytaj_dane_inwentaryzacje\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Lista ze sklepami`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE = \"all\"\n",
    "\n",
    "START_DATE = '' # Dobrać odpowiedni zakres w związku ze słabą jakościa danych na początku szeregu\n",
    "END_DATE = ''\n",
    "\n",
    "TEST_SIZE_DICT = {\n",
    "    \"oczyszczone\": 31,\n",
    "    \"odstajace\": 7,\n",
    "    \"inwentaryzacje\":7\n",
    "}\n",
    "\n",
    "MODEL_TYPES = [\"oczyszczone\", \"odstajace\", \"inwentaryzacje\"]\n",
    "\n",
    "ALL_STORES = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pozostałe funkcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_best_model(metrics_dict, metric='RMSE'):\n",
    "    return sorted(metrics_dict.items(), key=lambda x: x[1][metric])[0][0]\n",
    "\n",
    "def save_best_model(best_model, model_type, mode=\"test\"):\n",
    "    if best_model == \"ARIMAX\":\n",
    "        pickle.dump(forecaster_arimax, open(f'models/{mode}/{STORE}_{model_type}_best_model.pkl', 'wb'))\n",
    "        pickle.dump(X_test_selected.columns.tolist(), open(f'models/{mode}/selected_features/{STORE}_{model_type}_features.pkl', 'wb'))\n",
    "    elif best_model == \"Prophet\":\n",
    "        pickle.dump(forecaster_prophet, open(f'models/{mode}/{STORE}_{model_type}_best_model.pkl', 'wb'))\n",
    "        pickle.dump(X_test_selected2.columns.tolist(), open(f'models/{mode}/selected_features/{STORE}_{model_type}_features.pkl', 'wb'))\n",
    "    elif best_model == \"XGBoost\":\n",
    "        pickle.dump(gscv_x, open(f'models/{mode}/{STORE}_{model_type}_best_model.pkl', 'wb'))\n",
    "        pickle.dump(X_test_selected2.columns.tolist(), open(f'models/{mode}/selected_features/{STORE}_{model_type}_features.pkl', 'wb'))\n",
    "\n",
    "def get_data_reader(model_type):\n",
    "    if model_type == \"oczyszczone\":\n",
    "        return wczytaj_dane_oczyszczone\n",
    "    if model_type == \"odstajace\":\n",
    "        return wczytaj_dane_odstajace\n",
    "    if model_type == \"inwentaryzacje\":\n",
    "        return wczytaj_dane_inwentaryzacje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Master pętla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"oczyszczone\":\n",
    "        {\n",
    "            \"ARIMAX\":\n",
    "                {\n",
    "                    \"sp\": 4,\n",
    "                },\n",
    "            \"XGBoost\":\n",
    "                {\n",
    "                    \"window_lengths\": [4, 8, 12, 32],\n",
    "                    \"cv_window_length\": 52,\n",
    "                },\n",
    "            \"group_period\": 'W'\n",
    "        },\n",
    "    \"odstajace\":\n",
    "        {\n",
    "            \"ARIMAX\":\n",
    "                {\n",
    "                    \"sp\": 1,\n",
    "                },\n",
    "            \"XGBoost\":\n",
    "                {\n",
    "                    \"window_lengths\": [2, 4, 6, 12],\n",
    "                    \"cv_window_length\": 6,\n",
    "                },\n",
    "            \"group_period\": 'M'\n",
    "        },\n",
    "    \"inwentaryzacje\":\n",
    "        {\n",
    "            \"ARIMAX\":\n",
    "                {\n",
    "                    \"sp\": 1,\n",
    "                },\n",
    "            \"XGBoost\":\n",
    "                {\n",
    "                    \"window_lengths\": [2, 4, 6, 12],\n",
    "                    \"cv_window_length\": 6,\n",
    "                },\n",
    "            \"group_period\": 'M'\n",
    "            \n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = 'niestety'\n",
    "\n",
    "################################################################\n",
    "# - Obiekt do wyłapywania sklepów bez historii inwentaryzacji -#\n",
    "sklepy_bez_historii_inwentaryzacji = []\n",
    "#\n",
    "################################################################\n",
    "\n",
    "mode = 'test'                  # do weryfikowania plików w folderach i nie zaczynania pętli od początku\n",
    "for STORE in tqdm(ALL_STORES):\n",
    "    print(f\"------------------------ STORE: {STORE} ----------------------------\")\n",
    "\n",
    "    for MODEL_TYPE in MODEL_TYPES:\n",
    "        if (f\"{STORE}_{MODEL_TYPE}_best_model.pkl\" not in os.listdir(f\"./models/test/\")) | (f\"{STORE}_{MODEL_TYPE}_best_model.pkl\" not in os.listdir(f\"./models/pred/\")) :\n",
    "            print(f\"------ MODEL TYPE: {MODEL_TYPE} ------------\")\n",
    "            read_data = get_data_reader(model_type=MODEL_TYPE)\n",
    "\n",
    "            # ---------------------- read and preprocess data ---------------------------------\n",
    "\n",
    "            # data\n",
    "            y, X = read_data(start_date=START_DATE, end_date=END_DATE, store=STORE)\n",
    "            \n",
    "            # not empty df\n",
    "            if len(y) > 0:\n",
    "\n",
    "                # test_train_split\n",
    "                y_train, y_test, X_train, X_test = temporal_train_test_split(y, X, test_size=TEST_SIZE_DICT[MODEL_TYPE])\n",
    "\n",
    "                # fh\n",
    "                fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "                # feature selection\n",
    "                try:\n",
    "                    most_important_cols = get_most_important_cols(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, fh=fh)\n",
    "                    most_important_cols2 = get_most_important_cols2(X_train=X_train, y_train=y_train, n_features=4)\n",
    "\n",
    "                    X_train_selected, X_test_selected = X_train[most_important_cols], X_test[most_important_cols]\n",
    "                    X_train_selected2, X_test_selected2 = X_train[most_important_cols2], X_test[most_important_cols2]\n",
    "\n",
    "                except:\n",
    "                    most_important_cols2 = get_most_important_cols2(X_train=X_train, y_train=y_train, n_features=4)\n",
    "                    X_train_selected2, X_test_selected2 = X_train[most_important_cols2], X_test[most_important_cols2]\n",
    "\n",
    "                # ---------------------- train models ---------------------------------\n",
    "                metrics_dict = {}\n",
    "\n",
    "                # arimax\n",
    "                forecaster_arimax = AutoARIMA(sp=model_config[MODEL_TYPE][\"ARIMAX\"][\"sp\"], start_P=1, start_Q=1, max_P=8, max_Q=8, suppress_warnings=True)\n",
    "                try:\n",
    "                    forecaster_arimax.fit(y=y_train, X=X_train_selected)\n",
    "                    y_pred_arimax = forecaster_arimax.predict(X=X_test_selected, fh=fh) # predict\n",
    "                except:\n",
    "                    forecaster_arimax.fit(y=y_train, X=X_train_selected2)\n",
    "                    y_pred_arimax = forecaster_arimax.predict(X=X_test_selected2, fh=fh) # predict\n",
    "                metrics_dict[\"ARIMAX\"] = compute_metrics(y_test, y_pred_arimax).to_dict()['wynik']\n",
    "\n",
    "                # prophet\n",
    "                forecaster_prophet = Prophet(add_country_holidays={'country_name': 'Poland'})\n",
    "                forecaster_prophet.fit(y_train, X_train_selected2)\n",
    "\n",
    "                y_pred_prophet = forecaster_prophet.predict(X=X_test_selected2, fh=fh).rename(columns={\"yhat\": \"VALUE\"}) # predict\n",
    "                metrics_dict[\"Prophet\"] = compute_metrics(y_test, y_pred_prophet).to_dict()['wynik']\n",
    "\n",
    "                # xgboost\n",
    "                validation_size = len(fh)\n",
    "\n",
    "                #cv = SingleWindowSplitter(window_length=model_config[MODEL_TYPE][\"XGBoost\"][\"cv_window_length\"], fh=validation_size)\n",
    "\n",
    "                cv = SingleWindowSplitter(window_length=52, fh=validation_size)\n",
    "\n",
    "                regressor = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "\n",
    "                forecaster = make_reduction(\n",
    "                    regressor,\n",
    "                    scitype=\"tabular-regressor\",\n",
    "                    strategy=\"recursive\"\n",
    "                )\n",
    "\n",
    "                pipeline = TransformedTargetForecaster(\n",
    "                    [\n",
    "                        # (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=4)),\n",
    "                        # (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=2))),\n",
    "                        (\"model\", forecaster),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # hyperparameters grid to search over grid\n",
    "\n",
    "                param_grid = {\n",
    "                    #'model__window_length': model_config[MODEL_TYPE][\"XGBoost\"][\"window_lengths\"],\n",
    "                    'model__window_length': [2, 4, 8, 12],\n",
    "                    'model__estimator__max_depth': [3, 5, 6, 10, 15, 20],\n",
    "                    'model__estimator__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "                    'model__estimator__subsample': np.arange(0.5, 1.0, 0.1),\n",
    "                    'model__estimator__colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "                    'model__estimator__colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "                    'model__estimator__n_estimators': [100, 500, 1000],\n",
    "                }\n",
    "\n",
    "                # Do rozwiązania\n",
    "                gscv_x = ForecastingRandomizedSearchCV(\n",
    "                    pipeline,\n",
    "                    cv=cv,\n",
    "                    param_distributions=param_grid,\n",
    "                    # error_score='raise',\n",
    "                    n_iter=10,\n",
    "                    n_jobs=-1,\n",
    "                    random_state=42,\n",
    "                    verbose=3,\n",
    "                    error_score = 'raise'\n",
    "                )\n",
    "\n",
    "                # Część, którą musi dodać Kamil\n",
    "                if kamil == 'niestety':\n",
    "                    for i in [y_train, y_test, X_train_selected2, X_test_selected2]:\n",
    "                        i.index = i.index.to_period(model_config[MODEL_TYPE][\"group_period\"])\n",
    "                    fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "                gscv_x.fit(y=y_train, X=X_train_selected2)\n",
    "                y_pred_xgb = gscv_x.predict(X=X_test_selected2, fh=fh)\n",
    "\n",
    "                metrics_dict[\"XGBoost\"] = compute_metrics(y_test, y_pred_xgb).to_dict()['wynik']\n",
    "\n",
    "                # best - train/test\n",
    "                save_best_model(best_model=select_best_model(metrics_dict=metrics_dict), model_type=MODEL_TYPE)\n",
    "\n",
    "                # best - pelny model, nowe dane 2023\n",
    "                if select_best_model(metrics_dict=metrics_dict) == \"ARIMAX\":\n",
    "                    try:\n",
    "                        forecaster_arimax.fit(y=y, X=X[most_important_cols])\n",
    "                    except:\n",
    "                        forecaster_arimax.fit(y=y, X=X[most_important_cols2])\n",
    "                elif select_best_model(metrics_dict=metrics_dict) == \"Prophet\":\n",
    "                    forecaster_prophet.fit(y=y, X=X[most_important_cols2])\n",
    "                elif select_best_model(metrics_dict=metrics_dict) == \"XGBoost\":\n",
    "\n",
    "                    # Kolejna część, którą musi dodać Kamil\n",
    "                    if kamil == 'niestety':\n",
    "                        for i in [y,X]:\n",
    "                            i.index = i.index.to_period(model_config[MODEL_TYPE][\"group_period\"])\n",
    "                        fh = ForecastingHorizon(y.index, is_relative=False)\n",
    "\n",
    "                    gscv_x.fit(y=y, X=X[most_important_cols2])\n",
    "                save_best_model(best_model=select_best_model(metrics_dict=metrics_dict), model_type=MODEL_TYPE, mode=\"pred\")\n",
    "            \n",
    "            else:\n",
    "                sklepy_bez_historii_inwentaryzacji.append((STORE,MODEL_TYPE))\n",
    "                print(f\"------ MODEL TYPE: {MODEL_TYPE} HAS NO DATA !!! ------------\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"------ MODEL TYPE: {MODEL_TYPE} ALREADY IN DIRECTORY ------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklepy_bez_historii_inwentaryzacji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
